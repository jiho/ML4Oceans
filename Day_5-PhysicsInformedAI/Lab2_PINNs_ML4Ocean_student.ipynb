{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHn-F4M9rNaF"
   },
   "source": [
    "# **AI-informed physics, lab 2: PINNs**\n",
    "## *ML4Oceans Summer School 2022*\n",
    "##### Redouane Lguensat (IPSL/IRD) (https://redouanelg.github.io)\n",
    "\n",
    "References:\n",
    "* Raissi et al. 2017 https://arxiv.org/abs/1711.10561\n",
    "* https://cloud4scieng.org/2020/06/10/notes-on-deep-learning-and-differential-equations/\n",
    "* https://maziarraissi.github.io/PINNs/ \n",
    "* https://github.com/erfanhamdi/pinn-torch/tree/main/Burgers_Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MiuGb_PB7BU_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zI13SWFRUAc3"
   },
   "source": [
    "# PINN for solving Burgers equation \n",
    "\n",
    "Burgers Equation (https://en.wikipedia.org/wiki/Burgers%27_equation)\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial t} + u\\frac{\\partial u}{\\partial x} - \\nu \\frac{\\partial^2 u}{\\partial x^2} = 0,\n",
    "$$\n",
    "\n",
    "where $x \\in [-1, 1]$ and time $t \\in [0, 1]$.\n",
    "\n",
    "The parameter $\\nu$ is 0.01/pi (viscus Burgers equation case).\n",
    "\n",
    "**Boundary conditions:**\n",
    "\n",
    "the upper and lower boundary values are taken to be 0, i.e., $u(t,-1) = u(t,1)= 0$.  \n",
    "\n",
    " When t=0, the starting condition is taken to be $u(0,x) = -sin(pi*x)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eQ2jGtLesl9"
   },
   "source": [
    "**Goal**\n",
    "\n",
    "In this notebook we will use the PINN (Physical Informed Neural Network) idea from Raissi et al. (2017). The goal is to train a neural network that satisfies the differential equation and the boundary conditions.\n",
    "\n",
    "**Remark**\n",
    "\n",
    "In the general case we use also some samples from the solution $u$ for training (the data fidelity term of the loss function). But here we will see that the equation loss and the boundary loss are sufficient. The reason is that the form of the Burgers equation we are considering has a unique solution. So please keep in mind that this is not always the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Vdrn_4A2g63"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ds0xkEG_3ksG"
   },
   "source": [
    "Let us start by creating a training dataset by sampling from random positions in the boundaries. Remember that the inputs for the neural nets are $x$ and $t$ and the output is $u(x,t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gxbaYtU7B3f"
   },
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "\n",
    "nu = 0.01 / np.pi # the $\\nu$ constat in the Burgers equation\n",
    "N_u = 400   # number of training samples from the boundaries\n",
    "N_f = 2000  # number of collocation points\n",
    "\n",
    "x_upper = np.ones((N_u//4, 1), dtype=float)\n",
    "x_lower = np.ones((N_u//4, 1), dtype=float) * (-1)\n",
    "t_zero = np.zeros((N_u//2, 1), dtype=float)\n",
    "\n",
    "t_upper = np.random.rand(N_u//4, 1)\n",
    "t_lower = np.random.rand(N_u//4, 1)\n",
    "x_zero = (-1) + np.random.rand(N_u//2, 1) * (1 - (-1))\n",
    "\n",
    "# stack uppers, lowers and zeros:\n",
    "X_upper = np.hstack( (x_upper, t_upper) )\n",
    "X_lower = np.hstack( (x_lower, t_lower) )\n",
    "X_zero = np.hstack( (x_zero, t_zero) )\n",
    "\n",
    "# each one of these three arrays haS 2 columns, \n",
    "# now we stack them vertically, the resulting array will also have 2 \n",
    "# columns and 100 rows:\n",
    "X_u_train = np.vstack( (X_upper, X_lower, X_zero) )\n",
    "\n",
    "# shuffle X_u_train:\n",
    "index = np.arange(0, N_u)\n",
    "np.random.shuffle(index)\n",
    "X_u_train = X_u_train[index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-X3LEClMgpT"
   },
   "source": [
    "# PINN functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYKygC7_Mjmm"
   },
   "source": [
    "Create a Multilayer perceptron with Tanh activation function, that has 4 hidden layers with 20 neurons each. Write also a function that initialize the weights of the MLP using a Xavier_Normal initialization and initialize the biases with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKRUi4ZA7B1N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFDPH8J2Nk-W"
   },
   "source": [
    "Now that we have created our neural net that acts as $u(x,t)$, time to create the PINN loss function. Reminder that the PINN loss function here will consist of:\n",
    "* the boundary loss which is just a classical MSE loss between the outputs of the neural nets and the training boundary samples \n",
    "* the differential equation loss that satisfies\n",
    "$$\n",
    "\\mathcal{F(x,t)} = \\frac{\\partial u(x,t)}{\\partial t} + u(x,t)\\frac{\\partial u(x,t)}{\\partial x} - \\nu \\frac{\\partial^2 u(x,t)}{\\partial x^2} = 0,\n",
    "$$ for this one you will need to calculate derivatives, we already provide the torch function that does that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQ-VMDkNNPmh"
   },
   "outputs": [],
   "source": [
    "def gradient(func, x, order = 1):\n",
    "    for i in range(order):\n",
    "        func = torch.autograd.grad(func, x, grad_outputs = torch.ones_like(func), create_graph=True, retain_graph=True)[0]\n",
    "    return func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4R2adS2MPGLA"
   },
   "source": [
    "Now write the function $\\mathcal{F}$ and also the complete PINN loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvwyDbxfPErr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqInuHinPQPQ"
   },
   "source": [
    "The next provided functions are used to train the PINN model, we will use the L-BFGS optimizer, a second-order optimization algorithm, which converges quicker for this problem than ADAM, but has higher computational and memory requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vq05Q-xXNFhy"
   },
   "outputs": [],
   "source": [
    "h_lbfgs = []\n",
    "\n",
    "def train(model, X_u_train, X_f_train, u_train):\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(),lr=1,max_iter=100)\n",
    "    for iter in range(0,50):\n",
    "      def closure():\n",
    "          x_u = X_u_train[:, 0]\n",
    "          t_u = X_u_train[:, 1]\n",
    "          x_f = X_f_train[:, 0]\n",
    "          t_f = X_f_train[:, 1]\n",
    "          y_u = u_train\n",
    "          if torch.is_grad_enabled():\n",
    "            optimizer.zero_grad()\n",
    "          loss = PINNloss(model, x_f, t_f, x_u, t_u, y_u)\n",
    "          if loss.requires_grad:\n",
    "            loss.backward()\n",
    "          print(f\" iteration: {iter}  loss: {loss.item()}\")\n",
    "          h_lbfgs.append(loss.item())\n",
    "          return loss\n",
    "      optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPIjenWq7B6V"
   },
   "outputs": [],
   "source": [
    "# make X_f_train:\n",
    "from random import uniform\n",
    "np.random.seed(2022)\n",
    "\n",
    "X_f_train = np.zeros((N_f, 2), dtype=float)\n",
    "for row in range(N_f):\n",
    "    x = uniform(-1, 1)  # x range\n",
    "    t = uniform( 0, 1)  # t range\n",
    "\n",
    "    X_f_train[row, 0] = x \n",
    "    X_f_train[row, 1] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 1136,
     "status": "ok",
     "timestamp": 1661954113736,
     "user": {
      "displayName": "Redouane Lguensat",
      "userId": "03962813036841386011"
     },
     "user_tz": -120
    },
    "id": "0QIE3MtqGq7d",
    "outputId": "04390b54-12a9-41cf-e8ad-8df976f023e1"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_f_train[:,1], X_f_train[:,0], s=0.1, color='r', marker='x', label='colocation points')\n",
    "plt.scatter(X_u_train[:,1], X_u_train[:,0], s=2, color='b', marker='x', label='boundary training')\n",
    "plt.xlabel(r'$t$')\n",
    "plt.ylabel(r'$x$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJa28upSH0PD"
   },
   "outputs": [],
   "source": [
    "# add the boundary points to the collocation points:\n",
    "X_f_train = np.vstack( (X_f_train, X_u_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WOIiwvK7B-u"
   },
   "outputs": [],
   "source": [
    "# make u_train\n",
    "u_upper =  np.zeros((N_u//4, 1), dtype=float)\n",
    "u_lower =  np.zeros((N_u//4, 1), dtype=float) \n",
    "u_zero = -np.sin(np.pi * x_zero)  \n",
    "\n",
    "# stack them in the same order as X_u_train was stacked:\n",
    "u_train = np.vstack( (u_upper, u_lower, u_zero) )\n",
    "\n",
    "# match indices with X_u_train\n",
    "u_train = u_train[index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqDlKpIUEfcq"
   },
   "outputs": [],
   "source": [
    "X_u_train = torch.from_numpy(X_u_train).requires_grad_(True).float()\n",
    "X_f_train = torch.from_numpy(X_f_train).requires_grad_(True).float()\n",
    "u_train = torch.from_numpy(u_train).requires_grad_(True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1661954128482,
     "user": {
      "displayName": "Redouane Lguensat",
      "userId": "03962813036841386011"
     },
     "user_tz": -120
    },
    "id": "CdgJB1wW9fC4",
    "outputId": "8b41c63d-c3b4-41f5-9b56-d5492e030084"
   },
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "model = PINNBurgers()\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHR_HErt9ixl"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "iter = 0\n",
    "model.train()\n",
    "train(model, X_u_train, X_f_train, u_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 836,
     "status": "ok",
     "timestamp": 1661954234507,
     "user": {
      "displayName": "Redouane Lguensat",
      "userId": "03962813036841386011"
     },
     "user_tz": -120
    },
    "id": "B-MWaF-D1QXj",
    "outputId": "7f67a15a-b810-470e-82da-23f7baed632c"
   },
   "outputs": [],
   "source": [
    "plt.semilogy(h_lbfgs, label='L-BFGS')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH37wpS5J9Xx"
   },
   "source": [
    "# Plot PINN solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1661954237959,
     "user": {
      "displayName": "Redouane Lguensat",
      "userId": "03962813036841386011"
     },
     "user_tz": -120
    },
    "id": "6PAsuqhV9468",
    "outputId": "f7f0b5fa-3654-47ad-cb1e-c02f7f05670d"
   },
   "outputs": [],
   "source": [
    "x_size = 400\n",
    "t_size = 200\n",
    "\n",
    "x = torch.linspace(-1, 1, 400)\n",
    "t = torch.linspace( 0, 1, 200)\n",
    "X, T = torch.meshgrid(x, t)\n",
    "PINN_input = torch.cat((X.reshape(-1, 1), T.reshape(-1, 1)), 1)\n",
    "\n",
    "# PINN solution\n",
    "model.eval()\n",
    "sol = model(PINN_input).reshape(x_size, t_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "executionInfo": {
     "elapsed": 1377,
     "status": "ok",
     "timestamp": 1661954242063,
     "user": {
      "displayName": "Redouane Lguensat",
      "userId": "03962813036841386011"
     },
     "user_tz": -120
    },
    "id": "0rqpnFWm18zV",
    "outputId": "7566bfd5-c4ff-4e46-e838-8edb4df7547b"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "h = ax.imshow(sol.detach().numpy(), cmap='rainbow', vmin=-1, vmax=1,\n",
    "              extent=[t.numpy().min(), t.numpy().max(), x.numpy().min(), x.numpy().max()],\n",
    "              origin='lower', aspect='auto')\n",
    "cbar = fig.colorbar(h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWdqDu3CLdcB"
   },
   "source": [
    "Visualize the shock wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1661954246644,
     "user": {
      "displayName": "Redouane Lguensat",
      "userId": "03962813036841386011"
     },
     "user_tz": -120
    },
    "id": "b1N5agSkJ_Fd",
    "outputId": "d299b34b-3ada-4417-aa30-ff7afd568295"
   },
   "outputs": [],
   "source": [
    "plt.plot(x.numpy(), sol.detach().numpy()[:,0], label='begin t=0')\n",
    "plt.plot(x.numpy(), sol.detach().numpy()[:,-1], label='end t=1')\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$u(x,t)$')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
